# Content: openjdk-8-jdk + spark + livy + databand[spark]

ARG DOCKER_IMAGE_BASE=python:3.6
FROM ${DOCKER_IMAGE_BASE}

# Java installation:
RUN apt-get update -y -qq && \
    apt-get install -y -qq software-properties-common apt-transport-https && \
    apt-add-repository --yes -m 'deb http://security.debian.org/debian-security stretch/updates main' && \
    apt-get update -y -qq && apt-get install -y -qq openjdk-8-jdk

# Spark installation:
ENV SPARK_VERSION=2.4.5
ENV HADOOP_VERSION=2.7
RUN wget --no-verbose https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \
    tar -xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \
    mv spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /spark && \
    rm spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz

ENV PATH=$PATH:/spark/bin
ENV SPARK_HOME=/spark
ENV HADOOP_CONF_DIR=/etc/hadoop/conf

RUN pip install pyspark==${SPARK_VERSION} && \
    mv /spark/conf/spark-env.sh.template /spark/conf/spark-env.sh && \
    echo "export DBND_HOME=/app/" >> /spark/conf/spark-env.sh

# Livy installation:
ENV LIVY_VERSION=0.6.0
RUN wget --no-verbose http://archive.apache.org/dist/incubator/livy/${LIVY_VERSION}-incubating/apache-livy-${LIVY_VERSION}-incubating-bin.zip && \
    unzip apache-livy-${LIVY_VERSION}-incubating-bin.zip && \
    mv apache-livy-${LIVY_VERSION}-incubating-bin /livy && \
    rm apache-livy-${LIVY_VERSION}-incubating-bin.zip && \
    echo "livy.file.local-dir-whitelist = /" >> /livy/conf/livy.conf
ENV PATH=$PATH:/livy/bin

# install dbnd packages:
COPY ./dist/*.requirements.txt /dist/
RUN pip install -r /dist/dbnd.requirements.txt && \
    pip install -r /dist/dbnd-spark.requirements.txt && \
    pip install -r /dist/dbnd-test-scenarios.requirements.txt

COPY ./dist/*.whl /dist/
RUN pip install databand[spark] dbnd_test_scenarios --find-links /dist/ --no-index

EXPOSE 8998

CMD livy-server start && tail -f
