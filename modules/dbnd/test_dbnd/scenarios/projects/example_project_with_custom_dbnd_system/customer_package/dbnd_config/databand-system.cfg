# THIS IS DATABAND.AI CONFIGURATION FILE
[databand]
project_name = your_project_name

; modify so your module will be automatically loaded
; we are automatically loading package/file with the name "word_count
; module = example_pipeline
;verbose=False

[core]
sql_alchemy_conn = sqlite:///${DBND_SYSTEM}/dbnd.db

# supported clouds: ['local', 'gcp', 'aws']
environments = ['local']
databand_url = http://localhost:8080

[local]
root = ${DBND_HOME}/data


[output]
###
# TYPE = FILE FORMAT : for example   - file format
# supported types:  target, object, list, list_str, str, pandas_dataframe, pandas_df_dict, numpy_ndarray
# supported formats:  csv, pickle, txt, numpy (for numpy), json and others
#    you can add compression to the format:   csv.gz , txt.bz2
###
;target = csv
;object = pickle
;list = pickle
;list_str = txt
;list_int = json
;str = txt
;pandas_dataframe = csv
;pandas_df_dict = hdf5
;numpy_ndarray = numpy


[aws]
root = s3://your_bucket/your_root

[gcp]
root = gs://databand_examples

;[k8s-driver]
;type = k8s
;context = gke_YOUR-CLUSTER-on-k8s_us-central1-NAME
;registry = gcr.io/YOUR_REGISTRY-on-k8s


;[dataproc]
;zone = us-central1-f
;num_workers = 2
;
;master_machine_type = n1-standard-1
;master_disk_size = 100
;
;worker_machine_type = n1-standard-1
;worker_disk_size = 100


; [dataflow]
; project = your_project_id
; temp_location = gs://some_temp_location

[spark]
; jars = ['${DBND_HOME}/YOUR/JVM/PROJECT/target/lib/jsoup-1.11.3.jar']
; main_jar = ${DBND_HOME}/YOUR/JVM/PROJECT//target/ai.databand.examples-1.0-SNAPSHOT.jar

[SageMakerDeployTask]
execution_role_arn = arn:aws:iam::YOUR_NUMBER:role/SageMakerRole
