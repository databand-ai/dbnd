# Â© Copyright Databand.ai, an IBM Company 2022

import logging

from datetime import timedelta
from functools import partial
from time import sleep
from typing import Callable, Iterable, List, Tuple, Type, TypeVar
from uuid import UUID

from prometheus_client import Summary

from dbnd._core.utils.timezone import utcnow
from dbnd_monitor.base_component import BaseComponent
from dbnd_monitor.base_integration import BaseIntegration
from dbnd_monitor.base_integration_config import BaseIntegrationConfig
from dbnd_monitor.base_monitor_config import BaseMonitorConfig
from dbnd_monitor.integration_management_service import IntegrationManagementService
from dbnd_monitor.scheduler import Scheduler
from dbnd_monitor.utils.apm import transaction_scope
from dbnd_monitor.utils.logger_config import (
    configure_logging,
    configure_sending_monitor_logs,
)
from dbnd_monitor.utils.prometheus_tools import (
    integration_components_count,
    integration_iteration_time,
    monitor_integrations_count,
    monitor_iteration_time,
)


logger = logging.getLogger(__name__)


def _measure_integrations_count(integrations: List[BaseIntegration]) -> None:
    monitor_integrations_count.set(len(integrations))


def _measure_components_count(
    integration: BaseIntegration, components_list: List[BaseComponent]
) -> None:
    integration_components_count.labels(
        integration=integration.config.uid,
        monitor=integration.MONITOR_TYPE,
        fetcher=integration.config.fetcher_type,
    ).set(len(components_list))


def _measure_integration_iteration_time(integration: BaseIntegration) -> Summary:
    return integration_iteration_time.labels(
        integration=integration.config.uid,
        monitor=integration.MONITOR_TYPE,
        fetcher=integration.config.fetcher_type,
    ).time()


class MultiServerMonitor:
    """
    // Generated by WCA for GP
    MultiServerMonitor is a class that runs a periodic loop to sync data for defined
    integrations.  It is responsible for starting and stopping integrations, syncing
    data, and sending metrics to the backend server.

    When the monitor starts, it gets a list of all the integrations of the specified
    types from the integration management service. It stops any integrations that are no
    longer enabled in the configuration, starts any new integrations that are enabled,
    runs a sync iteration for each integration, and sends metrics to the backend server.

    The monitor also checks the intervals of each component and ensures that they are
    running at the correct interval.
    """

    def __init__(
        self,
        monitor_config: BaseMonitorConfig,
        integration_management_service: IntegrationManagementService,
        integration_types: List[Type[BaseIntegration]],
    ) -> None:
        self.monitor_config = monitor_config
        self.active_integrations = {}
        self.current_integrations = []
        self.integration_types = integration_types

        self.iteration = 0
        self.stop_at = (
            utcnow() + timedelta(seconds=self.monitor_config.stop_after)
            if self.monitor_config.stop_after
            else None
        )

        self.integration_management_service = integration_management_service
        self.task_scheduler = Scheduler()

    def _should_stop(self):
        if (
            self.monitor_config.number_of_iterations
            and self.iteration >= self.monitor_config.number_of_iterations
        ):
            return True

        if self.stop_at and utcnow() >= self.stop_at:
            return True

        return False

    def _stop_disabled_integrations(self, integrations: List[BaseIntegration]):
        for integration in integrations:
            integration_uid = integration.config.uid
            logger.info("Stopping disabled integration %s", integration_uid)
            try:
                integration.on_integration_disabled()
            except Exception:
                logger.exception(
                    "Fail executing on_integration_enabled for integration %s",
                    integration_uid,
                )
            self.active_integrations.pop(integration.config.uid)

    def _start_new_enabled_integrations(self, integrations: List[BaseIntegration]):
        for integration in integrations:
            integration_uid = integration.config.uid
            if integration_uid not in self.active_integrations:
                logger.info("Started syncing new integration %s", integration_uid)
                self.active_integrations[integration_uid] = {}
                try:
                    integration.on_integration_enabled()
                except Exception:
                    logger.exception(
                        "Fail executing on_integration_enabled for integration %s",
                        integration_uid,
                    )

    def _component_interval_is_met(
        self, integration_uid: UUID, component: BaseComponent
    ) -> bool:
        """
        Every component has an interval, make sure it doesn't run more often than the interval
        """
        last_heartbeat = self.active_integrations[integration_uid].get(
            component.identifier
        )
        if last_heartbeat is None:
            return True

        time_from_last_heartbeat = (utcnow() - last_heartbeat).total_seconds()
        return time_from_last_heartbeat >= component.sleep_interval

    def _heartbeat(self, integrations: List[BaseIntegration]):
        _measure_integrations_count(integrations)
        for integration in integrations:
            integration_uid = integration.config.uid
            logger.debug(
                "Starting new sync iteration for integration_uid=%s, iteration %d",
                integration_uid,
                self.iteration,
            )

            with _measure_integration_iteration_time(integration):
                # create new syncers with new config every heartbeat
                try:
                    components_list = integration.get_components()
                except Exception as exc:
                    logger.exception(exc)
                    continue

                _measure_components_count(integration, components_list)
                for component in components_list:

                    try:

                        if self._component_interval_is_met(integration_uid, component):
                            is_task_scheduled = self.try_schedule_component(
                                component, integration.config
                            )
                            if is_task_scheduled:
                                self.active_integrations[integration.config.uid][
                                    component.identifier
                                ] = utcnow()

                    except Exception:
                        logger.exception(
                            "Exception occurred during component execution"
                        )

    def try_schedule_component(
        self, component: BaseComponent, integration_config: BaseIntegrationConfig
    ) -> bool:
        task = partial(
            self.sync_component,
            component=component,
            integration_config=integration_config,
        )
        task_resource_group = str(integration_config.uid)
        is_task_scheduled = self.task_scheduler.try_schedule_task(
            task=task,
            task_id=f"{component.identifier};{task_resource_group}",
            group=task_resource_group,
        )
        return is_task_scheduled

    def sync_component(
        self, component: BaseComponent, integration_config: BaseIntegrationConfig
    ):
        try:
            component.refresh_config(integration_config)
            component.sync_once()
        except Exception:
            logger.exception("Exception occurred during component execution")

    def run(self):
        configure_logging(use_json=self.monitor_config.use_json_logging)

        if self.monitor_config.enable_sending_monitor_logs:
            self.set_remote_log_handler()

        while True:
            self.iteration += 1
            try:
                logger.debug("Starting %s iteration", self.iteration)
                self.run_once()
                name = getattr(self.monitor_config, "syncer_name", None)
                self.integration_management_service.send_metrics(name)
                logger.debug("Iteration %s done", self.iteration)
            except Exception:
                logger.exception("Unknown exception during iteration", exc_info=True)

            if self._should_stop():
                self.task_scheduler.wait_all_tasks()
                self._stop_disabled_integrations(self.current_integrations)
                break

            sleep(self.monitor_config.interval)

    def partition_integrations(
        self, new_integrations: List[BaseIntegration]
    ) -> Tuple[List[BaseIntegration], List[BaseIntegration]]:
        to_add = exclude_by_key(
            new_integrations, self.current_integrations, lambda i: i.config.uid
        )

        to_remove = exclude_by_key(
            self.current_integrations, new_integrations, lambda i: i.config.uid
        )

        return to_add, to_remove

    @monitor_iteration_time.time()
    def run_once(self):
        with transaction_scope("refresh_integrations"):
            integrations = self.get_integrations()
            to_add, to_remove = self.partition_integrations(integrations)
            self.current_integrations = integrations
            self._stop_disabled_integrations(to_remove)
            self._start_new_enabled_integrations(to_add)
        self._heartbeat(integrations)

    def get_integrations(self) -> List[BaseIntegration]:
        integrations = []
        for integration_type in self.integration_types:
            source_instance_uid = integration_type.get_source_instance_uid_or_none()
            configs = self.integration_management_service.get_all_integration_configs(
                monitor_type=integration_type.MONITOR_TYPE,
                syncer_name=self.monitor_config.syncer_name,
                source_instance_uid=source_instance_uid,
            )
            integrations.extend(
                [
                    integration_type.build_integration(config, self.monitor_config)
                    for config in configs
                ]
            )
        return integrations

    def set_remote_log_handler(self):

        if len(self.integration_types) == 1:
            configure_sending_monitor_logs(
                monitor_type=self.integration_types[0].MONITOR_TYPE,
                syncer_name=self.monitor_config.syncer_name,
                monitor_config=self.monitor_config,
            )
        else:
            logger.warning(
                "This monitor contains more than one integrations type, configuring sending monitor logs "
                "not possible"
            )


T = TypeVar("T")


# Generated by WCA for GP
def exclude_by_key(
    list_a: Iterable[T], list_b: Iterable[T], key: Callable[[T], bool]
) -> List[T]:
    """
    Returns a list of elements in list_a that are not present in list_b,
    where the comparison is made using the given key function.
    """
    b_keys = {key(item) for item in list_b}
    return [item for item in list_a if key(item) not in b_keys]
